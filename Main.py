# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15oW6v3iKg3QtMppkziATW_m_dPxCF-DK
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, f1_score
import numpy as np
import matplotlib.pyplot as plt

file_path = "/content/Dataset.csv"
data = pd.read_csv(file_path)

features = [
    "palabras_free_gratis",
    "num_enlaces_ip",
    "tamano_adjuntos_kb",
    "num_imagenes",
    "num_frases",
    "caracteres_repetidos",
    "envio_masivo"
]

X = data[features]
y = data["clase"]

accuracies = []
f1_scores = []
models = []  # Para guardar los modelos

print("Entrenando 50 modelos...")
for i in range(50):
    # Dividir datos en train/test con random_state diferente
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=i
    )

    # Crear árbol con mayor profundidad
    clf = DecisionTreeClassifier(
        criterion="gini",
        random_state=i,
        max_depth=10,  # Aumentar profundidad
        min_samples_split=5,  # Permitir splits con menos muestras
        min_samples_leaf=2    # Hojas con menos muestras
    )
    clf.fit(X_train, y_train)

    # Predicciones
    y_pred = clf.predict(X_test)

    # Métricas
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, pos_label="SPAM")

    accuracies.append(acc)
    f1_scores.append(f1)
    models.append(clf)

accuracies = np.array(accuracies)
f1_scores = np.array(f1_scores)

best_acc_idx = np.argmax(accuracies)
worst_acc_idx = np.argmin(accuracies)
best_f1_idx = np.argmax(f1_scores)
worst_f1_idx = np.argmin(f1_scores)

print("=" * 50)
print("RESULTADOS EN 50 REPETICIONES")
print("=" * 50)
print(f"Accuracy promedio: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}")
print(f"F1-score promedio: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}")

print("\n" + "=" * 50)
print("MEJORES Y PEORES CASOS")
print("=" * 50)
print(f"MEJOR Accuracy: Ejecución #{best_acc_idx + 1} = {accuracies[best_acc_idx]:.4f}")
print(f"PEOR Accuracy: Ejecución #{worst_acc_idx + 1} = {accuracies[worst_acc_idx]:.4f}")
print(f"MEJOR F1-score: Ejecución #{best_f1_idx + 1} = {f1_scores[best_f1_idx]:.4f}")
print(f"PEOR F1-score: Ejecución #{worst_f1_idx + 1} = {f1_scores[worst_f1_idx]:.4f}")

plt.figure(figsize=(12, 6))
plt.plot(range(1, 51), accuracies, label="Accuracy", marker="o", alpha=0.7)
plt.plot(range(1, 51), f1_scores, label="F1-score", marker="s", alpha=0.7)

# Marcar mejores y peores casos
plt.scatter(best_acc_idx + 1, accuracies[best_acc_idx],
           color='green', s=100, marker='^', label=f'Mejor Accuracy ({accuracies[best_acc_idx]:.4f})')
plt.scatter(worst_acc_idx + 1, accuracies[worst_acc_idx],
           color='red', s=100, marker='v', label=f'Peor Accuracy ({accuracies[worst_acc_idx]:.4f})')
plt.scatter(best_f1_idx + 1, f1_scores[best_f1_idx],
           color='darkgreen', s=100, marker='^', label=f'Mejor F1 ({f1_scores[best_f1_idx]:.4f})')
plt.scatter(worst_f1_idx + 1, f1_scores[worst_f1_idx],
           color='darkred', s=100, marker='v', label=f'Peor F1 ({f1_scores[worst_f1_idx]:.4f})')

plt.title("Variación de Accuracy y F1-score en 50 repeticiones")
plt.xlabel("Ejecución")
plt.ylabel("Valor")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

best_model = models[best_f1_idx]

print(f"\nMostrando árbol del mejor modelo (Ejecución #{best_f1_idx + 1})")
print(f"Profundidad del árbol: {best_model.get_depth()}")
print(f"Número de hojas: {best_model.get_n_leaves()}")

# Visualizar el mejor árbol
plt.figure(figsize=(20, 12))
plot_tree(best_model,
          feature_names=features,
          class_names=best_model.classes_,
          filled=True,
          fontsize=10,
          rounded=True)
plt.title(f"Árbol de decisión para clasificación HAM/SPAM\n(Mejor modelo - Ejecución #{best_f1_idx + 1}, F1-score: {f1_scores[best_f1_idx]:.4f})")
plt.tight_layout()
plt.show()
